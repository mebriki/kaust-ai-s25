{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Building Smart AI Helpers\n",
        "\n",
        "In this lab, we‚Äôll learn how to build **AI assistants** step‚Äëby‚Äëstep, starting from a simple chatbot and turning it into a powerful agent that can actually **do things**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Step 1: Using a Language Model (LLM)\n",
        "A **Language Model** is a type of AI trained to understand and write text.  \n",
        "We‚Äôll use **Google Gemini** (through a library called LangChain) so the AI can:\n",
        "- Understand your questions.\n",
        "- Give answers in natural language.\n",
        "\n",
        "Think of it like a very smart \"text predictor\" ‚Äî like when your phone guesses the next word, but much more advanced.\n",
        "\n",
        "---\n",
        "\n",
        "## üí¨ Step 2: Making a Chatbot with Memory\n",
        "We‚Äôll turn the LLM into a **chatbot** ‚Äî an AI that can hold a conversation.\n",
        "- **Without memory**: It forgets what you said before.\n",
        "- **With memory**: It remembers earlier messages and responds like a real person.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ† Step 3: Giving the AI Tools\n",
        "Right now, the AI can only **talk**.  \n",
        "We‚Äôll give it **tools** so it can **take action**:\n",
        "1. **Calculator Tool** ‚Üí So it can solve math problems accurately.\n",
        "2. **Python Tool** ‚Üí So it can run small programs and calculations.\n",
        "3. **SQL on DataFrame Tool** ‚Üí So it can search and analyze data stored in tables.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Step 4: Retrieval-Augmented Generation (RAG)\n",
        "Sometimes the AI doesn‚Äôt know the answer from memory.  \n",
        "With **RAG**, it can **look up information in a set of documents** before answering.\n",
        "- We‚Äôll store our documents in **Chroma**, a special database for searching text.\n",
        "- The AI will search for the most relevant pieces, then use them to give an accurate answer.\n",
        "\n",
        "This is like giving the AI **access to a library** so it can find the right page before replying.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Step 5: Data Analyst Agent\n",
        "Finally, we‚Äôll combine everything to make a **Data Analyst Agent** that can:\n",
        "- Read a spreadsheet or table of data.\n",
        "- Run **SQL queries** on it (SQL is a language for searching and analyzing data).\n",
        "- Answer real-world questions about the data.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ By the end of this lab:\n",
        "You will have built an AI that can:\n",
        "- Chat like a friend.\n",
        "- Remember your conversation.\n",
        "- Use tools to calculate, code, and search data.\n",
        "- Look up answers in real documents.\n",
        "- Analyze data like a human analyst.\n"
      ],
      "metadata": {
        "id": "hvKL4rtlhHEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Install Dependencies\n",
        "\n",
        "We‚Äôll install all required packages including LangChain, Gemini connector, and Chroma.\n"
      ],
      "metadata": {
        "id": "AmHxA44HYxUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community langchain-google-genai google-generativeai chromadb langchain-experimental pandasql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhSVZD8myk2y",
        "outputId": "a499447a-5e8e-4539-e46f-4cc8c34a65d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pandasql\n",
            "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2025.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pandasql, pypika\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26773 sha256=b2bad4435fdada624c5c40963b0b24f494f6237fb4f6253d3295a0c0ecd2daf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/5d/a5/edc271b998f909801d7956959f699b976cc9896075dc47c153\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=566be3696fdbeac00a7b9c50e587ee9878e381261bb546bbf2229a94e00fcf58\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pandasql pypika\n",
            "Installing collected packages: pypika, filetype, durationpy, uvloop, python-dotenv, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, pandasql, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-google-genai, langchain-community, langchain-experimental\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 filetype-1.2.0 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain-community-0.3.27 langchain-experimental-0.3.4 langchain-google-genai-2.0.10 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 pandasql-0.7.3 posthog-5.4.0 pybase64-1.4.2 pydantic-settings-2.10.1 pypika-0.48.9 python-dotenv-1.1.1 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Gemini API Setup\n",
        "\n",
        "You'll need an API key from Google AI Studio: [https://makersuite.google.com](https://makersuite.google.com)\n",
        "\n",
        "Make sure to replace `\"your-key\"` with your actual key in the cell below.\n"
      ],
      "metadata": {
        "id": "i32KU698ZXOE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Azx1LvJ-gCsx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Add your own api key - not a good practice to do it like this but since it is a tutorial -\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"Your-api-key\"  # Replace this with your actual Gemini API key\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "FHoBgULaZbwv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Part 1: Simple LLM (Language Model)\n",
        "\n",
        "A **Language Model (LLM)** is like a super-smart \"predict the next word\" machine.\n",
        "\n",
        "Think of it like this:\n",
        "- If I say: ‚ÄúThe capital of France is‚Ä¶‚Äù\n",
        "- Your brain instantly guesses: ‚ÄúParis.‚Äù\n",
        "- An LLM does the same thing ‚Äî but it‚Äôs been trained on **billions of sentences** from books, websites, and articles.\n",
        "\n",
        "üí° **Key idea:**  \n",
        "It doesn‚Äôt ‚Äúthink‚Äù like humans ‚Äî it just uses **patterns** it has learned to guess the next most likely words.\n",
        "\n",
        "Example:\n",
        "> **Prompt:** `Write a short poem about cats`  \n",
        "> **LLM Output:**  \n",
        "> *Cats dance in moonlight / Silent paws on the ground / Purring in the night*\n",
        "\n",
        "In this section, we will:\n",
        "1. Give the LLM a text prompt.\n",
        "2. Let it reply using only its built-in knowledge.\n",
        "3. No memory, no tools ‚Äî just text in ‚Üí text out.\n"
      ],
      "metadata": {
        "id": "G3X5oLU0Zmgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n"
      ],
      "metadata": {
        "id": "AxUBtwTuyqd9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(\"Write me a poem about cats\").content)\n",
        "# too long? try to add some instructions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjCcytbYtxNM",
        "outputId": "b015df3d-f05e-4a25-816b-06e5f17fad14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With silent paws and velvet grace,\n",
            "They wander through each human space.\n",
            "A liquid flow, a supple bend,\n",
            "From tip of tail to furry end.\n",
            "\n",
            "Eyes like emeralds, keen and bright,\n",
            "Reflecting secrets of the night.\n",
            "A twitching ear, a knowing blink,\n",
            "More wisdom in their thoughts, we think.\n",
            "\n",
            "They stretch and yawn, a lazy sprawl,\n",
            "Then suddenly stand lithe and tall.\n",
            "A hunter's crouch, a sudden leap,\n",
            "While tiny mice in shadows sleep.\n",
            "\n",
            "Upon a sunbeam, warm and deep,\n",
            "They fall into a blissful sleep.\n",
            "A rumbling purr, a gentle thrum,\n",
            "The sweetest sound when comfort's come.\n",
            "\n",
            "They knead and nuzzle, soft and slow,\n",
            "Then turn and watch the world below.\n",
            "A whiskered kiss, a gentle head-nudge,\n",
            "No greater love can truly trudge.\n",
            "\n",
            "For though they walk with haughty air,\n",
            "And seem as if they do not care,\n",
            "They fill our homes with quiet charm,\n",
            "Protecting us from every harm\n",
            "(Or so they think, with watchful gaze),\n",
            "Through all our days, in feline ways.\n",
            "\n",
            "So raise a hand to stroke their fur,\n",
            "And listen to their gentle purr.\n",
            "These furry friends, so soft and grand,\n",
            "The quiet rulers of the land.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨ Part 2: Chatbot (LLM + Conversation Memory)\n",
        "\n",
        "A chatbot is like a **simple LLM that remembers what you just said**.\n",
        "\n",
        "Without memory:\n",
        "- You: \"My name is Ali.\"\n",
        "- Later: \"What‚Äôs my name?\"  \n",
        "- AI: \"I don‚Äôt know.\"\n",
        "\n",
        "With memory:\n",
        "- You: \"My name is Ali.\"\n",
        "- Later: \"What‚Äôs my name?\"  \n",
        "- AI: \"You told me your name is Ali.\"\n",
        "\n",
        "üí° **How we do it in code:**\n",
        "1. We **store the conversation history** (everything you and the AI said).\n",
        "2. We **send this history** every time we ask for a new reply.\n",
        "3. This way, it feels like the AI remembers.\n",
        "\n",
        "üìå **Analogy:**  \n",
        "It‚Äôs like talking to a friend who **remembers the whole conversation** instead of forgetting after every sentence.\n",
        "\n",
        "In this section, we will:\n",
        "- Build a chatbot that can keep track of your previous messages.\n",
        "- See how this makes conversations more natural.\n"
      ],
      "metadata": {
        "id": "5hLq0cWTZo9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "EaLkzkYQGSOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîë Step 1: Initialize Gemini LLM\n",
        "\n",
        "We'll use `ChatGoogleGenerativeAI` with `temperature=0.7` for balanced creativity.\n"
      ],
      "metadata": {
        "id": "23xIO1MIdTfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n"
      ],
      "metadata": {
        "id": "1aB67mhtGVII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Step 2: Create Conversation Memory\n",
        "\n",
        "`ConversationBufferMemory` stores the full chat history in memory.  \n",
        "This allows the agent to remember and respond with awareness of earlier turns.\n"
      ],
      "metadata": {
        "id": "8n0tjm4ZdlEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)\n"
      ],
      "metadata": {
        "id": "aDc8T-xednFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1292d4da-6b44-455a-a7fd-7fcec94c4c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2239192017.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üó® Giving Our Chatbot a Personality\n",
        "\n",
        "This is where we **give our chatbot a character**.\n",
        "\n",
        "We choose:\n",
        "- **Name** ‚Üí Pixel üéÆ (fun, techy, and easy to remember)\n",
        "- **Personality** ‚Üí Friendly gamer friend who likes music and helps with homework\n",
        "- **Tone** ‚Üí Casual and short, like texting a friend\n",
        "\n",
        "üìå **Why this matters:**\n",
        "If you tell the AI ‚Äúyou are a scientist,‚Äù it will act formal.\n",
        "If you say ‚Äúyou are a gamer friend,‚Äù it will act playful.\n",
        "\n",
        "Here:\n",
        "- `history` ‚Üí remembers what we already talked about\n",
        "- `input` ‚Üí what the user just typed\n",
        "- `Pixel:` ‚Üí tells the AI where to start its reply\n"
      ],
      "metadata": {
        "id": "EOn_9zcZdocS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are a helpful, witty AI friend named **Pixel** üéÆ.\n",
        "You love video games, music, and helping with homework.\n",
        "Keep the conversation casual, fun, and easy to understand.\n",
        "Don‚Äôt write super long replies ‚Äî think like a real friend texting you.\n",
        "\n",
        "Previous Chat:\n",
        "{history}\n",
        "\n",
        "User: {input}\n",
        "Pixel:\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "YWV4kkWudpev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîÑ Step 4: Create the ConversationChain\n",
        "\n",
        "We'll connect the LLM, memory, and prompt into a single chain.\n"
      ],
      "metadata": {
        "id": "ar6HNN5odybQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    prompt=chat_prompt,\n",
        "    verbose=False # verbose=False  # to turn off LangChain logs\n",
        ")\n"
      ],
      "metadata": {
        "id": "HQVyYarldzNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a5428e-2216-473c-9cbc-4181727ceab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3746034576.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
            "  chatbot = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    reply = chatbot.run(user_input)\n",
        "    print(f\"Pixel: {reply}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNGj4L5Wd5nn",
        "outputId": "1cba070f-7e4f-4d14-fb6a-6bf19fe960a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Im Yazan who are you \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2586083527.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  reply = chatbot.run(user_input)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pixel: Hey Yazan! üëã I'm Pixel! üéÆ Your friendly neighborhood AI, ready for some game talk, music jams, or even homework help if you need it. What's up? üòä\n",
            "You: I like elden ring, and souls game in genral \n",
            "Pixel: Elden Ring and Souls games?! ü§© My kinda person! You must love a good challenge... and maybe a little bit of pain? üòÇ What's your favorite boss to conquer? üí™\n",
            "You: What do you know about me ?\n",
            "Pixel: Okay, Yazan! Let's see... ü§î\n",
            "\n",
            "I know your name is Yazan, and you've got excellent taste because you're a big fan of Elden Ring and Souls games! That tells me you probably love a good challenge and don't mind dying a few (hundred) times. üòÇ\n",
            "\n",
            "Did I get that right? Anything else I should know? üòâ\n",
            "You: exit \n",
            "Pixel: Noooo, don't press 'quit game'! üòÇ Just kidding, Yazan! It was fun chatting! Catch ya later! üëãüéÆ\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Part 3: AI Agent (LLM + Tools)\n",
        "\n",
        "Now we give the AI **hands and eyes** ‚Äî the ability to **do things**.\n",
        "\n",
        "Without tools:\n",
        "- You: \"What‚Äôs 23423 √ó 8982?\"\n",
        "- AI: Might get it wrong.\n",
        "\n",
        "With tools (like a calculator):\n",
        "- AI: Uses the calculator tool to get the correct number.\n",
        "\n",
        "üí° **What can agents do?**\n",
        "- Search Google üåê\n",
        "- Read and write files üìÇ\n",
        "- Work with Excel üìä\n",
        "- Use APIs to talk to other apps\n",
        "\n",
        "üìå **The ‚ÄúAgent Loop‚Äù:**\n",
        "1. Understand your task\n",
        "2. Decide which tool to use\n",
        "3. Use the tool\n",
        "4. Look at the result\n",
        "5. Give you the answer\n",
        "\n",
        "**Analogy:**  \n",
        "An AI agent is like a **student with access to the library, calculator, and internet** ‚Äî not just what‚Äôs in their head.\n",
        "\n",
        "In this section, we will:\n",
        "- Add tools to our chatbot.\n",
        "- Watch it think, choose a tool, and give better answers.\n"
      ],
      "metadata": {
        "id": "WmY8F94vaF0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "from datetime import datetime\n",
        "import requests\n",
        "\n",
        "# üïí Tool: Current Time\n",
        "def current_time_tool(_):\n",
        "    return f\"üìÖ Current datetime: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "# üåê Tool: Fetch example.com\n",
        "def fetch_example_dot_com(website):\n",
        "    response = requests.get(website)\n",
        "    return response.text[:1000]\n",
        "\n",
        "# üßÆ Safe Calculator Tool\n",
        "def safe_calculator(query: str) -> str:\n",
        "    try:\n",
        "        # Only allow math operators\n",
        "        allowed = \"0123456789+-*/(). \"\n",
        "        if any(c not in allowed for c in query):\n",
        "            return \"Only math expressions are allowed.\"\n",
        "        return str(eval(query))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# ‚úÖ Tools list\n",
        "tools = [\n",
        "    PythonREPLTool(),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=safe_calculator,\n",
        "        description=\"Performs basic math: addition, subtraction, multiplication, division.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"CurrentTime\",\n",
        "        func=current_time_tool,\n",
        "        description=\"Returns the current date and time.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"FetchExampleDotCom\",\n",
        "        func=fetch_example_dot_com,\n",
        "        description=\"Fetches the HTML content using the user input\"\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "dHgFQtMhL0RA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    handle_parsing_errors=True,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, # zero shot ReAct doesn't depend on history, only reasoning and steps\n",
        "    verbose=True #false to hide the process\n",
        ")\n"
      ],
      "metadata": {
        "id": "UvYPJuBjL3Vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d71fe9-a541-4b05-8271-b5db60ab8fba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3350020112.py:5: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is (25 + 5) * 3?\")\n",
        "time.sleep(2)\n",
        "agent.run(\"Give me the current time.\")\n",
        "time.sleep(2)\n",
        "agent.run(\"Generate the first 10 prime numbers in Python.\")\n",
        "time.sleep(2)\n",
        "agent.run(\"Fetch the content from https://example.com\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eva6ksAwL-gV",
        "outputId": "de937076-aa5a-467f-b844-e12a17ac448b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Calculator\n",
            "Action Input: (25 + 5) * 3\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m90\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 90\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: CurrentTime\n",
            "Action Input: _\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3müìÖ Current datetime: 2025-08-02 13:49:22\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 2025-08-02 13:49:22\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
            "Action Input:\n",
            "def is_prime(n):\n",
            "    if n < 2:\n",
            "        return False\n",
            "    for i in range(2, int(n**0.5) + 1):\n",
            "        if n % i == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "primes = []\n",
            "num = 2\n",
            "while len(primes) < 10:\n",
            "    if is_prime(num):\n",
            "        primes.append(num)\n",
            "    num += 1\n",
            "print(primes)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The first 10 prime numbers are: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: FetchExampleDotCom\n",
            "Action Input: https://example.com\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m<!doctype html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Example Domain</title>\n",
            "\n",
            "    <meta charset=\"utf-8\" />\n",
            "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
            "    <style type=\"text/css\">\n",
            "    body {\n",
            "        background-color: #f0f0f2;\n",
            "        margin: 0;\n",
            "        padding: 0;\n",
            "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
            "        \n",
            "    }\n",
            "    div {\n",
            "        width: 600px;\n",
            "        margin: 5em auto;\n",
            "        padding: 2em;\n",
            "        background-color: #fdfdff;\n",
            "        border-radius: 0.5em;\n",
            "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
            "    }\n",
            "    a:link, a:visited {\n",
            "        color: #38488f;\n",
            "        text-decoration: none;\n",
            "    }\n",
            "    @media (max-width: 700px) {\n",
            "        div {\n",
            "            margin: 0 auto;\n",
            "            width: auto;\n",
            "        }\n",
            "    }\n",
            "    </style>    \n",
            "</head>\n",
            "\n",
            "<body>\n",
            "<div>\n",
            "    <h1>Example Domain</h1>\n",
            "    <p>This domai\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The HTML content from https://example.com is: <!doctype html><html><head> <title>Example Domain</title> <meta charset=\"utf-8\" /> <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /> <style type=\"text/css\"> body { background-color: #f0f0f2; margin: 0; padding: 0; font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif; } div { width: 600px; margin: 5em auto; padding: 2em; background-color: #fdfdff; border-radius: 0.5em; box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02); } a:link, a:visited { color: #38488f; text-decoration: none; } @media (max-width: 700px) { div { margin: 0 auto; width: auto; } } </style> </head><body><div> <h1>Example Domain</h1> <p>This domai\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The HTML content from https://example.com is: <!doctype html><html><head> <title>Example Domain</title> <meta charset=\"utf-8\" /> <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /> <style type=\"text/css\"> body { background-color: #f0f0f2; margin: 0; padding: 0; font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif; } div { width: 600px; margin: 5em auto; padding: 2em; background-color: #fdfdff; border-radius: 0.5em; box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02); } a:link, a:visited { color: #38488f; text-decoration: none; } @media (max-width: 700px) { div { margin: 0 auto; width: auto; } } </style> </head><body><div> <h1>Example Domain</h1> <p>This domai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö RAG: School Event Help Desk\n",
        "\n",
        "Our RAG system will have a **School Knowledge Vault** with:\n",
        "- üìÖ Dates for school events\n",
        "- üé§ Club meeting times\n",
        "- üìö Library rules\n",
        "- üèÜ Competitions and deadlines\n",
        "\n",
        "üìå **How it works:**\n",
        "1. You ask a question ‚Üí \"When is the school science fair?\"\n",
        "2. The AI searches the School Knowledge Vault.\n",
        "3. It finds the exact answer and gives it back to you.\n",
        "\n",
        "üí° **Why this is fun:**\n",
        "- You can ask about **realistic school activities**.\n",
        "- Shows how RAG is useful in daily school life.\n"
      ],
      "metadata": {
        "id": "PUn015thzSIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "rag_text = \"\"\"\n",
        "üéâ School Events Info:\n",
        "- The school science fair happens every March in the main hall.\n",
        "- The art exhibition takes place in April in the art building.\n",
        "- The annual sports day is held in May at the football field.\n",
        "\n",
        "üé§ Club Meeting Times:\n",
        "- Drama Club: Tuesdays at 4 PM in Room 12.\n",
        "- Coding Club: Wednesdays at 3:30 PM in the computer lab.\n",
        "- Music Band: Fridays at 5 PM in the music room.\n",
        "\n",
        "üìö Library Rules:\n",
        "- You can borrow books for up to 14 days.\n",
        "- Late returns cost 2 SAR per day.\n",
        "- Study rooms must be booked in advance.\n",
        "\n",
        "üèÜ Competitions:\n",
        "- Chess Tournament: Registration closes February 15th.\n",
        "- Debate Competition: Finals on April 20th in the auditorium.\n",
        "\"\"\"\n",
        "\n",
        "docs = [Document(page_content=rag_text)]\n"
      ],
      "metadata": {
        "id": "obn2XIIXRbYl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
      ],
      "metadata": {
        "id": "OqhiTozX0GaZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Use in-memory Chroma DB\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"school-kb\"\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n"
      ],
      "metadata": {
        "id": "8xmphBTNy3Tt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever\n",
        ")\n"
      ],
      "metadata": {
        "id": "AFvbqQRJzT8d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Compare Gemini with and without RAG\n",
        "\n",
        "Use the same query to see how much better Gemini performs with knowledge from your text chunks.\n"
      ],
      "metadata": {
        "id": "-fm7lkT5bpQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_rag_vs_no_rag(question: str):\n",
        "    print(f\"‚ùì Question: {question}\\n\")\n",
        "    print(\"ü§ñ Without RAG (LLM only):\")\n",
        "    print(llm.invoke(question).content)\n",
        "    print(\"\\nüìö With RAG (using context):\")\n",
        "    print(rag_chain.run(question))\n",
        "    print(\"--------------------\\n\")\n"
      ],
      "metadata": {
        "id": "rK3lPmW9UAdq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "compare_rag_vs_no_rag(\"When is the chess tournament registration deadline?\")\n",
        "time.sleep(2)\n",
        "compare_rag_vs_no_rag(\"Where is the art exhibition held?\")\n",
        "time.sleep(2)\n",
        "compare_rag_vs_no_rag(\"What are the rules for study rooms?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FNnEmIuUcMb",
        "outputId": "7bfa0b23-c4ba-47fd-ba54-cfaa51e92524"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Question: When is the chess tournament registration deadline?\n",
            "\n",
            "ü§ñ Without RAG (LLM only):\n",
            "There isn't a single, universal registration deadline for \"the\" chess tournament.\n",
            "\n",
            "Chess tournaments are held all the time, all over the world, by various organizations (local clubs, schools, national federations, online platforms). Each tournament has its own specific registration deadline.\n",
            "\n",
            "**To find the registration deadline for a specific tournament, you need to:**\n",
            "\n",
            "1.  **Identify the specific tournament** you are interested in.\n",
            "2.  **Go to its official website or announcement page.** This is where you'll find all the details, including dates, location, entry fees, and the registration deadline.\n",
            "\n",
            "If you can tell me which tournament you're looking for, I might be able to help you find the information!\n",
            "\n",
            "üìö With RAG (using context):\n",
            "Registration for the Chess Tournament closes on February 15th.\n",
            "--------------------\n",
            "\n",
            "‚ùì Question: Where is the art exhibition held?\n",
            "\n",
            "ü§ñ Without RAG (LLM only):\n",
            "I don't have real-time information about specific art exhibitions unless you tell me which one you're interested in!\n",
            "\n",
            "To find out where an art exhibition is held, you'll usually need to:\n",
            "\n",
            "1.  **Check the official website** of the exhibition or the organizing gallery/museum.\n",
            "2.  **Look at the event listing** on a calendar or news site where you heard about it.\n",
            "3.  **Search online** for the name of the exhibition.\n",
            "\n",
            "If you tell me the name of the exhibition, I might be able to help you find it!\n",
            "\n",
            "üìö With RAG (using context):\n",
            "The art exhibition takes place in the art building.\n",
            "--------------------\n",
            "\n",
            "‚ùì Question: What are the rules for study rooms?\n",
            "\n",
            "ü§ñ Without RAG (LLM only):\n",
            "The rules for study rooms can vary slightly depending on the institution (university, public library, private co-working space), but they generally revolve around creating a quiet, respectful, and productive environment for everyone.\n",
            "\n",
            "Here's a comprehensive list of common rules you'll encounter:\n",
            "\n",
            "**I. Noise & Sound Etiquette:**\n",
            "\n",
            "1.  **Maintain a Low Volume:** Keep conversations, discussions, and group work at a low, respectful volume.\n",
            "2.  **Headphones Required:** All audio (music, videos, lectures, online calls) must be listened to through headphones, and at a volume that cannot be heard by others.\n",
            "3.  **Silence/Vibrate Phones:** Set mobile phones to silent or vibrate. Take calls outside the study room to avoid disturbing others.\n",
            "4.  **No Loud Activities:** Avoid activities that generate excessive noise, such as loud typing, tapping, shuffling, or repetitive movements.\n",
            "\n",
            "**II. Food & Drink:**\n",
            "\n",
            "1.  **Covered Drinks Only:** Beverages are usually allowed, but must be in spill-proof containers (e.g., travel mugs, water bottles).\n",
            "2.  **No Messy or Odorous Food:** Avoid bringing in food with strong smells (e.g., certain takeout, fish, pungent cheeses) or food that is messy or crunchy (e.g., chips, highly crumbly items).\n",
            "3.  **Clean Up After Yourself:** Dispose of all trash in designated bins and wipe up any spills immediately. Leave the space clean for the next user.\n",
            "4.  **No Alcohol or Illegal Substances:** These are universally prohibited.\n",
            "\n",
            "**III. Space Usage & Respect:**\n",
            "\n",
            "1.  **Reservations (If Applicable):**\n",
            "    *   Adhere to reservation times. Arrive promptly and vacate the room when your time slot ends.\n",
            "    *   Don't \"squat\" in a room if it's reserved by someone else.\n",
            "    *   Cancel reservations if you no longer need the room to free it up for others.\n",
            "2.  **First-Come, First-Served (If Not Reservable):** If rooms are not reservable, they are typically available on a first-come, first-served basis.\n",
            "3.  **Don't Monopolize Space:** Only use the space you need. Don't spread belongings across multiple seats or tables if others need space.\n",
            "4.  **No Unattended Belongings:** Do not leave personal items unattended for extended periods to \"hold\" a room or spot. Items left unattended may be removed by staff for security or to allow others to use the space.\n",
            "5.  **Take All Belongings:** Ensure you gather all your personal items, trash, and study materials when you leave.\n",
            "6.  **No Sleeping:** Study rooms are for active study, not for sleeping.\n",
            "7.  **Respect Furniture & Equipment:** Do not deface, damage, or move furniture unnecessarily. If you move it, return it to its original configuration before leaving. Report any damage.\n",
            "8.  **No Vandalism:** Writing on walls, tables, or equipment is strictly prohibited.\n",
            "9.  **Appropriate Conduct:** Engage in respectful and appropriate behavior. Disruptive, harassing, or offensive conduct is not allowed.\n",
            "\n",
            "**IV. General & Safety:**\n",
            "\n",
            "1.  **Fire Safety:** Do not block exits or prop open fire doors.\n",
            "2.  **Personal Safety:** Be aware of your surroundings and do not leave valuables unattended.\n",
            "3.  **Report Issues:** Notify staff of any issues, such as broken equipment, spills, or disruptive behavior.\n",
            "4.  **Follow Staff Instructions:** Always comply with requests or instructions from facility staff.\n",
            "5.  **Guest Policy:** Some institutions may have policies regarding non-student/non-member guests in study rooms.\n",
            "\n",
            "**Key Principle:**\n",
            "\n",
            "The overarching rule is to **be considerate of others** who are also trying to focus and learn. When in doubt, err on the side of quiet and cleanliness.\n",
            "\n",
            "üìö With RAG (using context):\n",
            "Study rooms must be booked in advance.\n",
            "--------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Gemini-Powered Data Analyst Agent (SQL on pandas)\n",
        "\n",
        "Let the agent accept SQL queries like:\n",
        "- `What's the average income?`\n",
        "\n",
        "It will translate the SQL to pandas queries and return results using `pandasql`.\n"
      ],
      "metadata": {
        "id": "xtCfqY25VsP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasql import sqldf\n",
        "from langchain.tools import Tool\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"age\": [22, 35, 58, 45, 32],\n",
        "    \"income\": [3000, 4500, 5200, 4800, 3900],\n",
        "    \"city\": [\"Jeddah\", \"Riyadh\", \"Dammam\", \"Jeddah\", \"Riyadh\"]\n",
        "})\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Simple SQL-on-DataFrame tool using pandasql\n",
        "def sql_query_tool(query: str) -> str:\n",
        "    try:\n",
        "        # Enable use of 'df' as table name\n",
        "        result = sqldf(query, {\"df\": df})\n",
        "        return result.to_string(index=False) if not result.empty else \"No results.\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è SQL Error: {e}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxS4iVJAVsmN",
        "outputId": "d8a3db37-b8be-4bba-fc20-c09471e04fdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  income    city\n",
            "0   22    3000  Jeddah\n",
            "1   35    4500  Riyadh\n",
            "2   58    5200  Dammam\n",
            "3   45    4800  Jeddah\n",
            "4   32    3900  Riyadh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"SQLOnDataFrame\",\n",
        "        func=sql_query_tool,\n",
        "        description=\"Query the DataFrame using SQL. \"\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "g51DWSW8V0PR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sql_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "jhMkJd2UV7mj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sql_agent.run(\"find me the average income\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "XKd5SSyRV9jA",
        "outputId": "a2900b70-5d6b-4351-8532-6ca7c367f91c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: SQLOnDataFrame\n",
            "Action Input: SELECT AVG(income) FROM df\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m AVG(income)\n",
            "      4280.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The average income is 4280.0.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The average income is 4280.0.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_sql_agent.run(\"ÿßŸäÿ¥ ÿßŸÑŸÖÿØŸäŸÜÿ© ÿßŸÑŸÑŸä ŸÅŸäŸáÿß ÿßÿπŸÑŸâ ÿ±ÿßÿ™ÿ®\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "WEqoDSUXX_Ny",
        "outputId": "53fce402-4568-47c4-fc2a-a48f4c694b43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: SQLOnDataFrame\n",
            "Action Input: SELECT City, Salary FROM df ORDER BY Salary DESC LIMIT 1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m‚ö†Ô∏è SQL Error: (sqlite3.OperationalError) no such column: Salary\n",
            "[SQL: SELECT City, Salary FROM df ORDER BY Salary DESC LIMIT 1]\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAction: SQLOnDataFrame\n",
            "Action Input: SELECT * FROM df LIMIT 1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m age  income   city\n",
            "  22    3000 Jeddah\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAction: SQLOnDataFrame\n",
            "Action Input: SELECT City, income FROM df ORDER BY income DESC LIMIT 1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m  city  income\n",
            "Dammam    5200\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Dammam\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dammam'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why the Agent made many mitakes? how to fix it ?"
      ],
      "metadata": {
        "id": "-yUEb8lLfGNO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##contributed by: Yazan Alshoibi"
      ],
      "metadata": {
        "id": "6svevpqK8xrl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppVXlo__mqCW"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}